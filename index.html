<!DOCTYPE html>
<!--Adapted from: https://visual.cs.brown.edu/workshops/necv2019/-->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Required meta tags -->
    
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <!--<link rel="stylesheet" href="./files/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">-->

    
    <style type="text/css">
  	body {
  		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
  		font-weight:300;
  		font-size:18px;
  		margin-left: auto;
  		margin-right: auto;
  		width: 1100px;
  	}
  	
  	h1 {
  		font-size:36px;
  		font-weight:300;
  	}
  	
  	.disclaimerbox {
  		background-color: #eee;		
  		border: 1px solid #eeeeee;
  		border-radius: 10px ;
  		-moz-border-radius: 10px ;
  		-webkit-border-radius: 10px ;
  		padding: 20px;
  	}
    
    .author_list {
      font-size: 11pt;
      color: #555;
    }
    .talk_title {
      font-size: 12pt;
    }

  	video.header-vid {
  		height: 140px;
  		border: 1px solid black;
  		border-radius: 10px ;
  		-moz-border-radius: 10px ;
  		-webkit-border-radius: 10px ;
  	}
  	
  	img.header-img {
  		height: 140px;
  		border: 1px solid black;
  		border-radius: 10px ;
  		-moz-border-radius: 10px ;
  		-webkit-border-radius: 10px ;
  	}
  	
  	img.rounded {
  		border: 1px solid #eeeeee;
  		border-radius: 10px ;
  		-moz-border-radius: 10px ;
  		-webkit-border-radius: 10px ;
  	}
  	
  	a:link,a:visited
  	{
  		color: #1367a7;
  		text-decoration: none;
  	}
  	a:hover {
  		color: #208799;
  	}
  	
    table { 
        border-collapse: collapse; 
    }
  	td.dl-link {
  		height: 160px;
  		text-align: center;
  		font-size: 22px;
  	}
    tr {
      border-top: 1pt solid black;
      border-bottom: 1pt solid black;
    }
    
    img.logo {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 256px;
    }
  	
  	.vert-cent {
  		position: relative;
  		top: 50%;
  		transform: translateY(-50%);
  	}
  	
  	hr
  	{
  		border: 0;
  		height: 1px;
  		background-image: linear-gradient(to right, rgba(0, 0, 0, 0.25), rgba(0, 0, 0, 0.25), rgba(0, 0, 0, 0.25));
  	}
  </style>

    <title>NECV 2022</title>
  </head>
  <body>
    
    <div class="container brownbrown w-75" align="center">
        <hr>
        <h1><b>New England Computer Vision Workshop</b></h1>
        <h3>MIT, Boston, MA</h3>
        <em><h3>Friday 9th December 2022</h3></em>
    </div>

    <div class="container" align="center">
        <img src="./files/header_img.jpg" width="90%" style="margin: 1em 0em 1em 0em; border: 1px solid #000"><br>
    </div>

    <div class="container w-75">
        <hr>
        <p>
        The New England Computer Vision Workshop (NECV) brings together researchers in computer vision and related areas for an informal exchange of ideas through a full day of presentations and posters. NECV typically attracts around 100 people from universities and industry research labs in New England. As in previous years, the workshop will focus on graduate student presentations.
        </p>

        <p>
          Welcome!<br><br>
          - <a href="http://web.mit.edu/phillipi">Phillip Isola</a> and <a href="https://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a>
        </p>
    </div>

    <div class="container w-75">
        <hr>
        <h3>Registration</h3>
        <p>
            Participation is free for all researchers at academic institutions. Academic researchers should register <a href="https://forms.gle/gvXxyLByXhRABGtz5" target="_blank">here</a>.
        </p>
        <p>
        For our industry friends, a limited number of registrations are available for a fee. Please contact <a href="mailto:samson@ai.mit.edu" target="_blank">Samson Timoner - samson@ai.mit.edu</a> for details.
        </p>
        
    </div>

    <div class="container w-75">
        <hr>
        <h3>Submission</h3>
        <p>
        Please submit a one-page PDF abstract using the <a href="https://media.icml.cc/Conferences/CVPR2023/cvpr2023-author_kit-v1_1-1.zip">CVPR 2023 rebuttal template</a> by email to <a href="mailto:necv2022mit@gmail.com">necv2022mit@gmail.com</a>. Abstracts are due by 11:59pm on <b>Mon Nov 21st</b>, 2022. Oral decisions will be released by Nov 28th..
        </p>

        <p>
        You may present work that has already been published, or work that is in progress. All submissions will be granted a poster presentation, and selected submissions from each institution will be granted 12-minute oral presentations. Post-docs and faculty may submit for poster presentations, but oral presentations are reserved for graduate students.
        </p>

        <p>
        There will be <em>no publications</em> resulting from the workshop, so presentations will not be considered "prior peer-reviewed work" according to any definition we are aware of. Thus, work presented at NECV can be subsequently submitted to other venues without citation.
        </p>

        <p>
        The workshop is after the CVPR supplemental deadline, so come and show off your new work in a friendly environment.
        </p>
    </div>

    <!--<div class="container w-75">
        <hr>
        <h3>Best Poster Competition Results</h3>

        <ul>
            <li></li>
        </ul>
    </div>-->

    <div class="container w-75">
        <hr>
        <h3>Logistics</h3>
        
        <h4>Tentative Schedule</h4>
        <p>
        </p><table>
            <tbody>
            <tr>
                <td width=150px>9:30-10:00</td>
                <td width=200px>Coffee, snacks, poster setup</td>
                <td></td>
            </tr>
            <tr>
                <td>10:00-10:15</td>
                <td>Welcome</td>
                <td></td>
            </tr>
            <tr>
                <td>10:15-11:30</td>
                <td>Oral presentations 1</td>
                <td>
                    <ol>
                      <li>
<span class="talk_title">Semantic Attention Flow Fields for Dynamic Scene Decomposition</span>
<br>
<span class="author_list">Yiqing Liang, Eliot Laidlaw, Alexander Meyerowitz, Srinath Sridhar, James Tompkin
 (Brown)</span>
</li>
<li>
<span class="talk_title">Discretization Invariant Learning on Neural Fields</span>
<br>
<span class="author_list">Clinton Wang, Polina Golland
 (MIT)</span>
</li>
<li>
<span class="talk_title">Image as Set of Points</span>
<br>
<span class="author_list">Xu Ma, Yuqian Zhou, Huan Wang, Can Qin, Bin Sun, Chang Liu, Yun Fu
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Designing Perceptual Puzzles by Differentiating Probabilistic Programs</span>
<br>
<span class="author_list">Kartik Chandra, Tzu-Mao Li, Josh Tenenbaum, Jonathan Ragan-Kelley
 (MIT)</span>
</li>
<li>
<span class="talk_title">StegaPos: Preventing Unwanted Crops and Replacements with Imperceptible Positional Embeddings</span>
<br>
<span class="author_list">Gokhan Egri, Todd Zickler
 (Harvard)</span>
</li>
</ol>
                </td>
            </tr>
            <tr>
              <td>11:30-11:45</td>
              <td>Sponsor talks</td>
              <td></td>
            </tr>
            <tr>
                <td>11:45-13:00</td>
                <td>Lunch (on your own)</td>
                <td></td>
            </tr>
            <tr>
                <td>13:00-14:30</td>
                <td>Poster presentations</td>
                <td>
                    <ul>
                      <li>
<span class="talk_title">Adaptive Trajectory Prediction via Transferable GNN</span>
<br>
<span class="author_list">Yi Xu, Lichen Wang, Yizhou Wang, Yun Fu
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Medical Image Representation Learning via Mutual Information Maximization</span>
<br>
<span class="author_list">Sidong Zhang, Madalina Fiterau
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">Rethinking 3DMM-Conditioned Face Synthesis</span>
<br>
<span class="author_list">Yiwen Huang, Zhiqiu Yu, Xinjie Yi, James Tompkin
 (Brown)</span>
</li>
<li>
<span class="talk_title">GPU-HC: GPU-Based Homotopy Continuation Solver for Minimal Problems in Computer Vision</span>
<br>
<span class="author_list">Chiang-Heng Chien, Hongyi Fan, Ahmad Abdelfattah, Elias Tsigaridas, Stanimire Tomov, Benjamin Kimia
 (Brown)</span>
</li>
<li>
<span class="talk_title">Learning Object-Centric Dynamic Modes from Video and Emerging Properties</span>
<br>
<span class="author_list">Armand Comas, Christian Fernandez, Sandesh Ghimire, Haolin Li, Mario Sznaier, Octavia Camps
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Comparing Correspondences: Video Prediction with Correspondence-wise Losses</span>
<br>
<span class="author_list">Daniel Geng, Max Hamilton, Andrew Owens
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">EVAL: Explainable Video Anomaly Localization</span>
<br>
<span class="author_list">Ashish Singh, Michael J. Jones, Erik Learned-Miller
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">Multiview Curve Correspondence for Curve Grouping and Reconstruction</span>
<br>
<span class="author_list">Yilin Zheng, Chiang-Heng Chien, Benjamin Kimia
 (Brown)</span>
</li>
<li>
<span class="talk_title">Exploring visual prompts for adapting large-scale models</span>
<br>
<span class="author_list">Hyojin Bahng, Ali Jahanian, Swami Sankaranarayanan, Phillip Isola​
 (MIT)</span>
</li>
<li>
<span class="talk_title">On the capability of humans and reinforcement learning agents to generalize across noisy worlds</span>
<br>
<span class="author_list">Serena Bono, Spandan Madan, Ishaan Grover, Hanspeter Pfister, Gabriel Kreiman
 (Harvard)</span>
</li>
<li>
<span class="talk_title">Is that Pruning Experiment Really Fair? – On the Role of Trainability in Network Pruning</span>
<br>
<span class="author_list">Huan Wang, Can Qin, Yue Bai, and Yun Fu
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Mitral Regurgitation Detection Using Cardiac Imaging Data</span>
<br>
<span class="author_list">Ke Xiao, James Priest, Erik Learned-Miller, Madalina Fiterau
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">Using spatio-temporal information in weather radar data to detect and track communal bird roosts</span>
<br>
<span class="author_list">Gustavo Perez, Wenlong Zhao, Zezhou Cheng, Maria Carolina T. D. Belotti, Yuting Deng, Victoria F. Simons, Elske Tielens, Jeffrey F. Kelly, Kyle G. Horton, Subhransu Maji, Daniel Sheldon
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes</span>
<br>
<span class="author_list">Rahul Sajnani, Adrien Poulenard, Jivitesh Jain, Radhika Dua, Leonidas J. Guibas, Srinath Sridhar
 (Brown)</span>
</li>
<li>
<span class="talk_title">Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting</span>
<br>
<span class="author_list">Jie Ji, Gen Li, Xiaolong Ma
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Joint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4</span>
<br>
<span class="author_list">William Berrios, Arturo Deza
 (MIT)</span>
</li>
<li>
<span class="talk_title">Divide and Compose with Score Based Generative Models</span>
<br>
<span class="author_list">Sandesh Ghimire, Armand Comas, Davin Hill, Aria Masoomi, Octavia Camps*, Jennifer Dy*
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">UniverSeg: Universal Medical Image Segmentation</span>
<br>
<span class="author_list">Victor Ion Butoi, Jose J. Ortiz, Tianyu Ma, John Guttag, Mert R. Sabuncu, Adrian V. Dalca
 (MIT)</span>
</li>
<li>
<span class="talk_title">Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction</span>
<br>
<span class="author_list">David Klee, Ondrej Biza, Robert Platt, and Robin Walters
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Accidental Turntables: Learning 3D Pose by Watching Objects Turn</span>
<br>
<span class="author_list">Zezhou Cheng, Matheus Gadelha, Subhransu Maji
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">Using 3D Models in Virtual Reality to Address Small Data Challenges in Human/Animal Pose Estimation</span>
<br>
<span class="author_list">Max Leblang, Le Jiang, Xiaofei Huang, Sarah Ostadabbas
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">PlanarRecon: Real-time 3D Plane Detection and Reconstruction from Posed Monocular Videos</span>
<br>
<span class="author_list">Yiming Xie, Matheus Gadelha, Fengting Yang, Xiaowei Zhou, Huaizu Jiang
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">Persistent Nature: A Generative Model of Unbounded 3D Worlds</span>
<br>
<span class="author_list">Lucy Chai, Richard Tucker, Zhengqi Li, Phillip Isola, Noah Snavely
 (MIT)</span>
</li>
<li>
<span class="talk_title">ToRF++: 3D reconstruction and novel view synthesis for fast motion using Time-of-Flight cameras</span>
<br>
<span class="author_list">Mikhail Okunev, Benjamin Attal, Marc Mapeke, Christian Richardt, Matthew O’Toole, James Tompkin
 (Brown)</span>
</li>
<li>
<span class="talk_title">Skeleton-based 3D shape generation and editing</span>
<br>
<span class="author_list">Dmitrii Petrov, Vikas Thamizharasan, Matheus Gadelha, Vova Kim, Siddhartha Chaudhuri, Evangelos Kalogerakis
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">Cross-view Action Recognition via Contrastive View-invariant Representations</span>
<br>
<span class="author_list">Yuexi Zhang, Dan Luo, Balaji Sundareshan, Octavia Camps, Mario Sznaier
 (Northeastern)</span>
</li>
<li>
<span class="talk_title">PARTICLE: Part Discovery and Contrastive Learning for Fine-grained Recognition</span>
<br>
<span class="author_list">Oindrila Saha, Subhransu Maji
 (Umass Amherst)</span>
</li>
<li>
<span class="talk_title">Generalized Relative Neighborhood Graph (GRNG) for Similarity Search</span>
<br>
<span class="author_list">Cole Foster, Berk Sevilmis, Benjamin Kimia
 (Brown)</span>
</li>
<li>
<span class="talk_title">Spatio-Visual Fusion-Based Person Re-Identification for Overhead Fisheye Images</span>
<br>
<span class="author_list">Mertcan Cokbas, Prakash Ishwar, Janusz Konrad
 (BU)</span>
</li>
<li>
<span class="talk_title">Natural Language Descriptions of Deep Visual Features</span>
<br>
<span class="author_list">Evan Hernandez, Sarah Schwettmann, David Bau, Teona Bagashvili, Antonio Torralba, Jacob Andreas
 (MIT)</span>
</li>
<li>
<span class="talk_title">Unsupervised feature correlation network for localizing breast cancer using prior mammograms</span>
<br>
<span class="author_list">Jun Bai, Annie Jin, Madison Admas, Shanglin Zhou, Caiwen Ding, Clifford Yang, and Sheida Nabavi
 (UConn)</span>
</li>
<li>
<span class="talk_title">Leveraging Temporal Context in Low Representational Power Regimes</span>
<br>
<span class="author_list">Camilo Fosco, Souyoung Jin, Emilie Josephs, Aude Oliva (MIT)</span>
</li>
<li>
<span class="talk_title">Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!</span>
<br>
<span class="author_list">Zaid Khan, Vijay Kumar BG, Samuel Schulter, Xiang Yu, Yun Fu, Manmohan Chandraker (Northeastern)</span>
</li>
<li>
<span class="talk_title">Parameter-Efficient Masking Networks</span>
<br>
<span class="author_list">Yue Bai, Huan Wang, Xu Ma, Yitian Zhang, Zhiqiang Tao, Yun Fu (Northeastern)</span>
</li>
<li>
<span class="talk_title">Analysis of Saliency Frameworks on Fine Grained Image Classification</span>
<br>
<span class="author_list">Rangel Daroya, Aaron Sun, and Subhransu Maji (Umass Amherst)</span>
</li>
</ul>
                </td>
            </tr>
            <tr>
                <td>14:30-15:45</td>
                <td>Oral presentations 2</td>
                <td>
                    <ol start="6">
                      <li>
                      <span class="talk_title">ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model</span>
                      <br>
                      <span class="author_list">Rao Fu, Xiao Zhan, Yiwen Chen, Daniel Ritchie, Srinath Sridhar
                       (Brown)</span>
                      </li>
                      <li>
                      <span class="talk_title">Exploring Consistency in Cross-Domain Transformer for Domain Adaptive Semantic Segmentation</span>
                      <br>
                      <span class="author_list">Kaihong Wang, Donghyun Kim, Rogerio Feris, Kate Saenko, Margrit Betke
                       (BU)</span>
                      </li>
                      <li>
                      <span class="talk_title">Learning Regular Rearrangements of Objects in Rooms</span>
                      <br>
                      <span class="author_list">Qiuhong Anna Wei, Sijie Ding, Jeong Joon Park, Rahul Sajnani, Adrien Poulenard, Srinath Sridhar, Leonidas Guibas
                       (Brown)</span>
                      </li>
                      <li>
                      <span class="talk_title">Analysis of Explainability Frameworks on Fine Grained Image Classification</span>
                      <br>
                      <span class="author_list">Rangel Daroya, Aaron Sun, Subhransu Maji
                       (UMass Amherst)</span>
                      </li>
                      <li>
                      <span class="talk_title">Momentum is All You Need for Adaptive Optimization</span>
                      <br>
                      <span class="author_list">Yizhou Wang, Yue Kang, Can Qin, Huan Wang, Yi Xu, Yulun Zhang, Yun Fu
                       (Northeastern)</span>
                      </li>
                    </ol>
                </td>
            </tr>
            <tr>
                <td>15:45-16:00</td>
                <td>Coffee</td>
                <td></td>
            </tr>
            <tr>
                <td>16:00-17:15</td>
                <td>Oral presentations 3</td>
                <td>
                    <ol start="11">
                      <li>
                      <span class="talk_title">Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes</span>
                      <br>
                      <span class="author_list">Fabien Delattre, David Dirnfeld, Phat Nguyen, Stephen Scarano, Pedro Miraldo, Michael J. Jones, Erik Learned-Miller
                       (UMass Amherst)</span>
                      </li>
                      <li>
                      <span class="talk_title">Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners</span>
                      <br>
                      <span class="author_list">Zitian Chen, Yikang Shen, Mingyu Ding, Zhenfang Chen, Hengshuang Zhao, Erik Learned-Miller, Chuang Gan
                       (UMass Amherst)</span>
                      </li>
                      <li>
                      <span class="talk_title">Compound Tokens: Channel Fusion for Vision-Language Representation Learning</span>
                      <br>
                      <span class="author_list">Maxwell Aladago, AJ Piergiovanni
                       (Dartmouth)</span>
                      </li>
                      <li>
                      <span class="talk_title">Diagnosing Error in Human-object Interaction Detectors</span>
                      <br>
                      <span class="author_list">Fangrui Zhu, Weidi Xie, Yiming Xie, Huaizu Jiang
                       (Northeastern)</span>
                      </li>
                      <li>
                      <span class="talk_title">Towards using Adversarially Robust Features as alternative features for rendering of Full-Field Foveated Metamers</span>
                      <br>
                      <span class="author_list">Raphaela Kang, Arturo Deza
                       (MIT)</span>
                      </li>
                    </ol>
                </td>
            </tr> 
            </tbody>
        </table>
        <p></p>

        <!--<h4>WiFi</h4>
        <p>
        Logon to "Brown Guest" and accept the terms. Alternatively, if your home institution participates in eduroam, then you can also use eduroam to connect wirelessly while on our campus.
        </p>-->

        <h4>Getting here</h4>
        <p>
            The workshop will be held at the <b>MIT-IBM Watson AI Lab (314 Main Street, Cambridge, MA, 02142).</b><br>
            <br>
            You will need a photo ID to get in the building (a driver's license or any other photo ID is fine).<br>
            <br>
            Getting there: The building is right above the Kendall T stop. There are also several (expensive) parking garages nearby, one of the closest is 33 Amherst St, Cambridge MA 02142, which costs $45 per day. Street parking is not easy to get in the Kendall area.
        </p>
        <!--<iframe src="./NECV 2019_files/embed.html" width="75%" frameborder="0" style="border:0;" allowfullscreen=""></iframe>
        
        <br><img src="./NECV 2019_files/alumnaehall.jpg" width="75%" style="padding: 1em 0em 1em 0em"><br>
    
        <p>
            <b>By train:</b> From the station, campus is a 15 minute walk up College Hill, or a short taxi ride. <em>From Boston:</em> MBTA and Amtrak services run regularly. Take a train south from South Station or Back Bay to Providence, RI. MBTA service is on the <a href="https://www.mbta.com/schedules/CR-Providence/timetable?direction_id=0">Providence/Stoughton line</a>. MBTA fares are $12.50 and takes 1:00-1:10 hr from South Station; Amtrak takes 40 minutes and costs $14 for early booking on the Northeastern train or up to $40-60 for the Acela train. <em>From New Haven, New London, NYC:</em> Amtrak service north to Providence, RI.
        </p>

        <p>
            <b>By coach:</b> <a href="https://peterpanbus.com/">Peter Pan</a> coach services run throughout New England; come to Providence (downtown) and either walk (15 mins), take a local bus (RIPTA, $2), or use taxi services.
        </p>

        <p>
            <b>Local buses:</b> <a href="https://www.ripta.com/">Rhode Island Public Transit Authority (RIPTA)</a> has a schedule and map, with real-time information through the "Transit" app. Buses 1, 32, 33 run to campus from downtown; walking is ~15 minutes.
        </p>

        <p>
            <b>By car:</b> Brown has a visitor parking lot which costs $15 per day. <a href="https://www.brown.edu/about/administration/transportation/about/visitor-parking">Instructions here</a>. Entrance is on Brook Street <a href="https://www.google.com/maps/@41.8227839,-71.3992847,19z">(map)</a>. On-street parking within campus is extremely limited. Street parking ~10 minutes walk away has fewer restrictions.
        </p>-->
    </div>

    <div class="container w-75">
        <hr>
        <h3>Sponsorship</h3>
        <p>We are grateful to the MIT-IBM Watson AI Lab for providing the venue and logistical support. We thank Boston Dynamics, Shipin.ai, Google for providing funding.</p>
        
        <img class="logo" src="./files/mit-ibm_logo.png"/><br>
        <img class="logo" src="./files/bd_logo.png"/><br>
        <img class="logo" src="./files/shipin_logo.jpg"/><br>
        <img class="logo" src="./files/google_logo.png"/><br>
    </div>

    <div class="container w-75">
        <hr>
        <h3>Acknowledgements</h3>
        <p>
            Thank you to Samson Timoner and Luke Inglis for helping us arrange NECV 2022. Thank you also to the steering committee: James Tompkin, Benjamin Kimia, Todd Zickler, Yun Raymond Fu, Octavia Camps, Kate Saenko, Erik Learned-Miller, and Subhransu Maji.
        </p>
        <h4>Past Years</h4>
        <ul>
            <li>2019 - Brown University <a href="https://visual.cs.brown.edu/workshops/necv2019/">(website)</a></li>
            <li>2018 - Harvard University <a href="https://projects.iq.harvard.edu/necv2018/">(website)</a></li>
            <li>2017 - Northeastern University <a href="https://web.northeastern.edu/smilelab/necv2017/index.html">(website)</a></li>
            <li>2016 - Boston University <a href="http://vision.cs.uml.edu/necv2016.html">(website)</a></li>
            <li>2015 - UMass Amherst <a href="https://people.cs.umass.edu/~smaji/nevm2015/">(website)</a></li>
        </ul>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <!--<script src="./NECV 2019_files/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="./NECV 2019_files/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="./NECV 2019_files/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>-->
  
</body></html>